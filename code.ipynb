{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tanvigunjal/Generating-Adversarial-Perturbations-using-Generative-Models/blob/main/code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jEL_-wgv8RE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf969cf0-9f90-4849-8c9b-d9cadcf6070a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "pxOBG9ou3PXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ro9jL5rpc8Sw"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "from datetime import datetime as dt\n",
        "\n",
        "import torch\n",
        "from torch import optim, nn\n",
        "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision import transforms as T\n",
        "from torchvision import models, datasets\n",
        "#from generator.generator import ResnetGenerator, weights_init\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "\n",
        "#import opendatasets as od\n",
        "import os\n",
        "from random import randint\n",
        "import urllib\n",
        "import zipfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rM_lheI5enD",
        "outputId": "2d313d86-8a25-4eaa-8133-6309e8b0534d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "# Define device to use (CPU or GPU). CUDA = GPU support for PyTorch\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VSv8K0PDb8Hg"
      },
      "outputs": [],
      "source": [
        "# Retrieve data directly from Stanford data source\n",
        "!wget http://cs231n.stanford.edu/tiny-imagenet-200.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yiyRXEKjcJOc"
      },
      "outputs": [],
      "source": [
        "# # Unzip raw zip file\n",
        "# !unzip 'tiny-imagenet-200.zip'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Refactor val directory\n",
        "\n",
        "# import io\n",
        "# import pandas as pd\n",
        "# import glob\n",
        "# import os\n",
        "# from shutil import move\n",
        "# from os.path import join\n",
        "# from os import listdir, rmdir\n",
        "\n",
        "# target_folder = '/content/tiny-imagenet-200/val/'\n",
        "\n",
        "# val_dict = {}\n",
        "# with open(target_folder + 'val_annotations.txt', 'r') as f:\n",
        "#     for line in f.readlines():\n",
        "#         split_line = line.split('\\t')\n",
        "#         val_dict[split_line[0]] = split_line[1]\n",
        "        \n",
        "# paths = glob.glob(target_folder + 'images/*')\n",
        "# paths[0].split('/')[-1]\n",
        "# for path in paths:\n",
        "#     file = path.split('/')[-1]\n",
        "#     folder = val_dict[file]\n",
        "#     if not os.path.exists(target_folder + str(folder)):\n",
        "#         os.mkdir(target_folder + str(folder))\n",
        "        \n",
        "# for path in paths:\n",
        "#     file = path.split('/')[-1]\n",
        "#     folder = val_dict[file]\n",
        "#     dest = target_folder + str(folder) + '/' + str(file)\n",
        "#     move(path, dest)\n",
        "    \n",
        "# os.remove('/content/tiny-imagenet-200/val/val_annotations.txt')\n",
        "# rmdir('/content/tiny-imagenet-200/val/images')"
      ],
      "metadata": {
        "id": "EgYAEu96qd86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5CMtxs9rqga_"
      },
      "outputs": [],
      "source": [
        "# Define main data directory\n",
        "DATA_DIR = '/content/tiny-imagenet-200' # Original images come in shapes of [3,64,64]\n",
        "\n",
        "# Define training and validation data paths\n",
        "TRAIN_DIR = os.path.join(DATA_DIR, 'train') \n",
        "VALID_DIR = os.path.join(DATA_DIR, 'val')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZfhOJC2vVWy1"
      },
      "outputs": [],
      "source": [
        "# Helper functions\n",
        "# Functions to display single or a batch of sample images\n",
        "def imshow(img):\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "    \n",
        "def show_batch(dataloader):\n",
        "    dataiter = iter(dataloader)\n",
        "    images, labels = dataiter.next()    \n",
        "    imshow(make_grid(images)) # Using Torchvision.utils make_grid function\n",
        "    \n",
        "def show_image(dataloader):\n",
        "    dataiter = iter(dataloader)\n",
        "    images, labels = dataiter.next()\n",
        "    random_num = randint(0, len(images)-1)\n",
        "    imshow(images[random_num])\n",
        "    label = labels[random_num]\n",
        "    print(f'Label: {label}, Shape: {images[random_num].shape}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KnWwEFqKWYoN"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ! ------------------------- TRAIN SETTINGS --------------------------- ! \n",
        "# magnitude of perturbation\n",
        "mag_in = 20.0\n",
        "batch_size = 4\n",
        "testBatchSize = 4\n",
        "lr = 0.0002\n",
        "beta1 = 0.5\n",
        "\n",
        "\n",
        "nEpochs = 10\n",
        "threads = 4\n",
        "seed = 123\n",
        "MaxIter = 50\n",
        "MaxIterTest = 1700 # During Test keep it 1700, 160 train\n",
        "# experiment name, output folder\n",
        "expname = '/content/gdrive/MyDrive/MLCYB/GAP'\n",
        "#expname = '/content/gdrive/MyDrive/dangerous'\n",
        "# path to starting checkpoint\n",
        "checkpoint = ''\n",
        "# mode, train or test\n",
        "mode = 'test'\n",
        "# universal\" or \"imdep\" (image dependent)\n",
        "perturbation_type = \"universal\"\n",
        "# targeted = 0.....200(classes) ; untargeted = -1\n",
        "target = -1\n",
        "path_to_U_noise = '/content/gdrive/MyDrive/MLCYB/GAP/U_input_noise.txt'\n",
        "explicit_U = '/content/gdrive/MyDrive/MLCYB/GAP/U_out/U_epoch_10_foolrat_34.16149139404297.pth'\n",
        "fool_mod = 'res'\n",
        "\n",
        "# !-------------- Global variables ----------------------!\n",
        "# train loss history\n",
        "train_loss_history = []\n",
        "test_loss_history = []\n",
        "test_acc_history = []\n",
        "test_fooling_history = []\n",
        "best_fooling = 0\n",
        "itr_accum = 0\n",
        "\n",
        "\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "# make directories\n",
        "if not os.path.exists(expname):\n",
        "    os.mkdir(expname)\n",
        "\n",
        "if perturbation_type == 'universal':\n",
        "  if not os.path.exists(expname + '/U_out'):\n",
        "    os.mkdir(expname + '/U_out')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UKk3MrjjVeAx"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !------------------------ DATA PRE-PROCESSING ---------------------------- !\n",
        "# !--------------------- GAN ------------------------- !\n",
        "gpu_ids = '0'\n",
        "gpulist = [int(i) for i in gpu_ids.split(',')]\n",
        "#gpulist = []\n",
        "n_gpu = len(gpulist)\n",
        "print('Running with n_gpu: ', n_gpu)\n",
        "\n",
        "\n",
        "model_dimension = 256\n",
        "center_crop = 224\n",
        "\n",
        "\n",
        "mean_arr = [0.485, 0.456, 0.406]\n",
        "stddev_arr = [0.229, 0.224, 0.225]\n",
        "normalize = T.Normalize(mean=mean_arr,\n",
        "                                 std=stddev_arr)\n",
        "data_transform = T.Compose([\n",
        "    T.Resize(model_dimension),  # Resize images to 299 x 299\n",
        "    T.CenterCrop(center_crop),  # Center crop image\n",
        "    T.ToTensor(),  # Converting cropped images to tensors\n",
        "    normalize,\n",
        "])\n",
        "\n",
        "if mode == 'train':\n",
        "  data_set = torchvision.datasets.ImageFolder(TRAIN_DIR, transform = data_transform)\n",
        "  train_dataloader = DataLoader(data_set,num_workers=2, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "  \n",
        "test_set = torchvision.datasets.ImageFolder(VALID_DIR, transform = data_transform)\n",
        "test_dataloader = DataLoader(test_set,num_workers=2, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TT4dJmET3r4U",
        "outputId": "a4e58a3b-ab7e-4d9a-ae7d-bce2c83f8603"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running with n_gpu:  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PDUJNXunV8Fd"
      },
      "outputs": [],
      "source": [
        "#train_dataloader = generate_dataloader(TRAIN_DIR, \"train\", transform=data_transform)\n",
        "#val_dataloader = generate_dataloader(VALID_DIR, \"val\", transform=data_transform)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_mod = torch.load(\"/content/gdrive/MyDrive/MLCYB/saved_models/models/resnet18_64_full_model.pt\")\n",
        "pretrained_mod.load_state_dict(torch.load('/content/gdrive/MyDrive/MLCYB/saved_models/models/resnet18_256_64.pt'))\n",
        "pretrained_mod = pretrained_mod.cuda(gpulist[0])\n",
        "pretrained_mod.eval()\n",
        "pretrained_mod.volatile = True"
      ],
      "metadata": {
        "id": "GhEDv11zTAaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8qCdQ0kAJMts"
      },
      "outputs": [],
      "source": [
        "# !------------------- RESNET BLOCK ----------------------- !\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import init\n",
        "import functools\n",
        "from torch.autograd import Variable\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "def weights_init(m, act_type='relu'):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        if act_type == 'selu':\n",
        "            n = float(m.in_channels * m.kernel_size[0] * m.kernel_size[1])\n",
        "            m.weight.data.normal_(0.0, 1.0 / math.sqrt(n))\n",
        "        else:\n",
        "            m.weight.data.normal_(0.0, 0.02)        \n",
        "        if hasattr(m.bias, 'data'):\n",
        "            m.bias.data.fill_(0)\n",
        "    elif classname.find('BatchNorm2d') != -1:\n",
        "        m.weight.data.normal_(1.0, 0.02)\n",
        "        m.bias.data.fill_(0)\n",
        "\n",
        "\n",
        "\n",
        "class ResnetGenerator(nn.Module):\n",
        "    def __init__(self, input_nc, output_nc, ngf, norm_type, act_type='selu', use_dropout=False, n_blocks=6, padding_type='reflect', gpu_ids=[]):\n",
        "        assert(n_blocks >= 0)\n",
        "        super(ResnetGenerator, self).__init__()\n",
        "\n",
        "        self.name = 'resnet'\n",
        "        self.input_nc = input_nc\n",
        "        self.output_nc = output_nc\n",
        "        self.ngf = ngf\n",
        "        self.gpulist = gpu_ids\n",
        "        self.num_gpus = len(self.gpulist)\n",
        "\n",
        "        use_bias = norm_type == 'instance'\n",
        "\n",
        "        if norm_type == 'batch':\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        elif norm_type == 'instance':\n",
        "            norm_layer = nn.InstanceNorm2d\n",
        "\n",
        "        if act_type == 'selu':\n",
        "            self.act = nn.SELU(True)\n",
        "        else:\n",
        "            self.act = nn.ReLU(True)\n",
        "\n",
        "        model0 = [nn.ReflectionPad2d(3),\n",
        "                  nn.Conv2d(input_nc, ngf, kernel_size=7, padding=0,\n",
        "                            bias=use_bias),\n",
        "                  norm_layer(ngf),\n",
        "                  self.act]\n",
        "\n",
        "        n_downsampling = 2\n",
        "        for i in range(n_downsampling):\n",
        "            mult = 2**i\n",
        "            model0 += [nn.Conv2d(ngf * mult, ngf * mult * 2, kernel_size=3,\n",
        "                                 stride=2, padding=1, bias=use_bias),\n",
        "                       norm_layer(ngf * mult * 2),\n",
        "                       self.act]\n",
        "\n",
        "        if self.num_gpus == 1:\n",
        "            mult = 2**n_downsampling\n",
        "            for i in range(n_blocks):\n",
        "                model0 += [ResnetBlock(ngf * mult, padding_type=padding_type, norm_layer=norm_layer, use_dropout=use_dropout, use_bias=use_bias)]\n",
        "        elif self.num_gpus == 2:\n",
        "            model1 = []\n",
        "            mult = 2**n_downsampling\n",
        "            mid = int(n_blocks / 2)\n",
        "            for i in range(mid):\n",
        "                model0 += [ResnetBlock(ngf * mult, padding_type=padding_type, norm_layer=norm_layer, use_dropout=use_dropout, use_bias=use_bias)]\n",
        "            for i in range(n_blocks - mid):\n",
        "                model1 += [ResnetBlock(ngf * mult, padding_type=padding_type, norm_layer=norm_layer, use_dropout=use_dropout, use_bias=use_bias)]\n",
        "        elif self.num_gpus == 3:\n",
        "            model1 = []\n",
        "            model2 = []\n",
        "            mult = 2**n_downsampling\n",
        "            mid1 = int(n_blocks / 5)\n",
        "            mid2 = mid1 + int((n_blocks - mid1) / 4.0 * 3)\n",
        "            # mid = int(n_blocks / 2)\n",
        "            for i in range(mid1):\n",
        "                model0 += [ResnetBlock(ngf * mult, padding_type=padding_type, norm_layer=norm_layer, use_dropout=use_dropout, use_bias=use_bias)]\n",
        "            for i in range(mid1, mid2):\n",
        "                model2 += [ResnetBlock(ngf * mult, padding_type=padding_type, norm_layer=norm_layer, use_dropout=use_dropout, use_bias=use_bias)]\n",
        "            for i in range(mid2, n_blocks):\n",
        "                model1 += [ResnetBlock(ngf * mult, padding_type=padding_type, norm_layer=norm_layer, use_dropout=use_dropout, use_bias=use_bias)]\n",
        "\n",
        "        if self.num_gpus >= 2:\n",
        "            for i in range(n_downsampling):\n",
        "                mult = 2**(n_downsampling - i)\n",
        "                model1 += [nn.ConvTranspose2d(ngf * mult, int(ngf * mult / 2),\n",
        "                                            kernel_size=3, stride=2,\n",
        "                                            padding=1, output_padding=1,\n",
        "                                            bias=use_bias),\n",
        "                        norm_layer(int(ngf * mult / 2)),\n",
        "                        self.act]\n",
        "            model1 += [nn.ReflectionPad2d(3)]\n",
        "            model1 += [nn.Conv2d(ngf, output_nc, kernel_size=7, padding=0)]\n",
        "            model1 += [nn.Tanh()]\n",
        "        else:\n",
        "            for i in range(n_downsampling):\n",
        "                mult = 2**(n_downsampling - i)\n",
        "                model0 += [nn.ConvTranspose2d(ngf * mult, int(ngf * mult / 2),\n",
        "                                            kernel_size=3, stride=2,\n",
        "                                            padding=1, output_padding=1,\n",
        "                                            bias=use_bias),\n",
        "                        norm_layer(int(ngf * mult / 2)),\n",
        "                        self.act]\n",
        "            model0 += [nn.ReflectionPad2d(3)]\n",
        "            model0 += [nn.Conv2d(ngf, output_nc, kernel_size=7, padding=0)]\n",
        "            model0 += [nn.Tanh()] \n",
        "\n",
        "        self.model0 = nn.Sequential(*model0)\n",
        "        #self.model0.cuda(self.gpulist[0])\n",
        "        if self.num_gpus == 2:\n",
        "            self.model1 = nn.Sequential(*model1)\n",
        "            self.model1.cuda(self.gpulist[1])\n",
        "        if self.num_gpus == 3:\n",
        "            self.model2 = nn.Sequential(*model2)\n",
        "            self.model2.cuda(self.gpulist[2])\n",
        "\n",
        "    def forward(self, input):\n",
        "        #input = input.cuda(self.gpulist[0])\n",
        "        input = self.model0(input)\n",
        "        if self.num_gpus == 3:\n",
        "            input = input.cuda(self.gpulist[2])\n",
        "            input = self.model2(input)\n",
        "        if self.num_gpus == 2:\n",
        "            input = input.cuda(self.gpulist[1])\n",
        "            input = self.model1(input)\n",
        "        return input\n",
        "\n",
        "\n",
        "# Define a resnet block\n",
        "class ResnetBlock(nn.Module):\n",
        "    def __init__(self, dim, padding_type, norm_layer, use_dropout, use_bias):\n",
        "        super(ResnetBlock, self).__init__()\n",
        "        self.conv_block = self.build_conv_block(dim, padding_type, norm_layer, use_dropout, use_bias)\n",
        "\n",
        "    def build_conv_block(self, dim, padding_type, norm_layer, use_dropout, use_bias):\n",
        "        conv_block = []\n",
        "        p = 0\n",
        "        if padding_type == 'reflect':\n",
        "            conv_block += [nn.ReflectionPad2d(1)]\n",
        "        elif padding_type == 'replicate':\n",
        "            conv_block += [nn.ReplicationPad2d(1)]\n",
        "        elif padding_type == 'zero':\n",
        "            p = 1\n",
        "        else:\n",
        "            raise NotImplementedError('padding [%s] is not implemented' % padding_type)\n",
        "\n",
        "        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=p, bias=use_bias),\n",
        "                       norm_layer(dim),\n",
        "                       nn.ReLU(True)]\n",
        "        if use_dropout:\n",
        "            conv_block += [nn.Dropout(0.5)]\n",
        "\n",
        "        p = 0\n",
        "        if padding_type == 'reflect':\n",
        "            conv_block += [nn.ReflectionPad2d(1)]\n",
        "        elif padding_type == 'replicate':\n",
        "            conv_block += [nn.ReplicationPad2d(1)]\n",
        "        elif padding_type == 'zero':\n",
        "            p = 1\n",
        "        else:\n",
        "            raise NotImplementedError('padding [%s] is not implemented' % padding_type)\n",
        "        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=p, bias=use_bias),\n",
        "                       norm_layer(dim)]\n",
        "\n",
        "        return nn.Sequential(*conv_block)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = x + self.conv_block(x)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44pnf1YSwHqC"
      },
      "outputs": [],
      "source": [
        "#@\n",
        "ngf = 64\n",
        "if not explicit_U:\n",
        "#will use model paralellism if more than one gpu specified\n",
        "    netG = ResnetGenerator(3, 3, ngf, norm_type='batch', act_type='relu', gpu_ids=gpulist)\n",
        "\n",
        "    # resume from checkpoint if specified\n",
        "    #checkpoint = ''\n",
        "    if checkpoint:\n",
        "        if os.path.isfile(checkpoint):\n",
        "            print(\"=> loading checkpoint '{}'\".format(checkpoint))\n",
        "            netG.load_state_dict(torch.load(checkpoint, map_location=lambda storage, \n",
        "                                            loc: storage))\n",
        "            print(\"=> loaded checkpoint '{}'\".format(checkpoint))\n",
        "        else:\n",
        "            print(\"=> no checkpoint found at '{}'\".format(checkpoint))\n",
        "            netG.apply(weights_init)\n",
        "    else:\n",
        "      netG.apply(weights_init)\n",
        "\n",
        "    # setup optimizer\n",
        "    optimizer = 'adam'\n",
        "    if optimizer == 'adam':\n",
        "      optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "    elif optimizer == 'sgd':\n",
        "      optimizerG = optim.SGD(netG.parameters(), lr=lr, momentum=0.9)\n",
        "\n",
        "    criterion_pre = nn.CrossEntropyLoss()\n",
        "    #criterion_pre = criterion_pre.cuda(gpulist[0])\n",
        "\n",
        "    # fixed noise for universal perturbation\n",
        "    if perturbation_type == 'universal':\n",
        "      noise_data = np.random.uniform(0, 255, center_crop * center_crop * 3)\n",
        "      if checkpoint:\n",
        "        if path_to_U_noise:\n",
        "            noise_data = np.loadtxt(path_to_U_noise)\n",
        "            np.savetxt(expname + '/U_input_noise.txt', noise_data)\n",
        "        else:\n",
        "            noise_data = np.loadtxt(expname + '/U_input_noise.txt')\n",
        "      else:\n",
        "          np.savetxt(expname + '/U_input_noise.txt', noise_data)\n",
        "      im_noise = np.reshape(noise_data, (3, center_crop, center_crop))\n",
        "      im_noise = im_noise[np.newaxis, :, :, :]\n",
        "      im_noise_tr = np.tile(im_noise, (batch_size, 1, 1, 1))\n",
        "      noise_tr = torch.from_numpy(im_noise_tr).type(torch.FloatTensor)\n",
        "\n",
        "      im_noise_te = np.tile(im_noise, (testBatchSize, 1, 1, 1))\n",
        "      noise_te = torch.from_numpy(im_noise_te).type(torch.FloatTensor)\n",
        "      print('Hi')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fPMXPeRSwlJf"
      },
      "outputs": [],
      "source": [
        "def train(epoch):\n",
        "    netG.train()\n",
        "    global itr_accum\n",
        "    global optimizerG\n",
        "\n",
        "    for itr, (image, _) in enumerate(train_dataloader, 1):\n",
        "        if itr > MaxIter:\n",
        "            break\n",
        "\n",
        "        if target == -1:\n",
        "            # least likely class in nontargeted case\n",
        "            pretrained_label_float = pretrained_mod(image.cuda(gpulist[0]))\n",
        "            _, target_label = torch.min(pretrained_label_float, 1)\n",
        "        else:\n",
        "            # targeted case\n",
        "            target_label = torch.LongTensor(image.size(0))\n",
        "            target_label.fill_(target)\n",
        "            target_label = target_label.cuda(gpulist[0])\n",
        "\n",
        "        itr_accum += 1\n",
        "        if optimizer == 'sgd':\n",
        "            lr_mult = (itr_accum // 1000) + 1\n",
        "            optimizerG = optim.SGD(netG.parameters(), lr=lr/lr_mult, momentum=0.9)\n",
        "\n",
        "        image = image.cuda(gpulist[0])\n",
        "\n",
        "        ## generate per image perturbation from fixed noise\n",
        "        if perturbation_type == 'universal':\n",
        "            delta_im = netG(noise_tr)\n",
        "        else:\n",
        "            delta_im = netG(image)\n",
        "\n",
        "        delta_im = normalize_and_scale(delta_im, 'train')\n",
        "\n",
        "        netG.zero_grad()\n",
        "\n",
        "        recons = torch.add(image.cuda(gpulist[0]), delta_im.cuda(gpulist[0]))\n",
        "\n",
        "        # do clamping per channel otp\n",
        "        for cii in range(3):\n",
        "            recons[:,cii,:,:] = recons[:,cii,:,:].clone().clamp(image[:,cii,:,:].min(), image[:,cii,:,:].max())\n",
        "\n",
        "        output_pretrained = pretrained_mod(recons.cuda(gpulist[0]))\n",
        "\n",
        "        # attempt to get closer to least likely class, or target\n",
        "        loss = torch.log(criterion_pre(output_pretrained, target_label))\n",
        "\n",
        "        loss.backward()\n",
        "        optimizerG.step()\n",
        "\n",
        "        train_loss_history.append(loss.item())\n",
        "        print(\"===> Epoch[{}]({}/{}) loss: {:.4f}\".format(epoch, itr, len(train_dataloader), loss.item()))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test():\n",
        "    if not explicit_U:\n",
        "      #netG = ResnetGenerator(3, 3, 64, norm_type='batch', act_type='relu', gpu_ids=gpulist)\n",
        "      netG.eval()\n",
        "    correct_recon = 0\n",
        "    correct_orig = 0\n",
        "    fooled = 0\n",
        "    total = 0\n",
        "\n",
        "    if perturbation_type == 'universal':\n",
        "        if explicit_U:        \n",
        "          U_loaded = torch.load(explicit_U)\n",
        "          U_loaded = U_loaded.expand(testBatchSize, U_loaded.size(1), U_loaded.size(2), U_loaded.size(3))\n",
        "          delta_im = normalize_and_scale(U_loaded, 'test')\n",
        "        else:\n",
        "          delta_im = netG(noise_te)\n",
        "          delta_im = normalize_and_scale(delta_im, 'test')\n",
        "\n",
        "    for itr, (image, class_label) in enumerate(test_dataloader):\n",
        "        if itr > MaxIterTest:\n",
        "            break\n",
        "\n",
        "        image = image.cuda(gpulist[0])\n",
        "\n",
        "        if perturbation_type == 'imdep':\n",
        "            delta_im = netG(image)\n",
        "            delta_im = normalize_and_scale(delta_im, 'test')\n",
        "\n",
        "        recons = torch.add(image.cuda(gpulist[0]), delta_im.cuda(gpulist[0]))\n",
        "\n",
        "        # do clamping per channel\n",
        "        for cii in range(3):\n",
        "            recons[:,cii,:,:] = recons[:,cii,:,:].clone().clamp(image[:,cii,:,:].min(), image[:,cii,:,:].max())\n",
        "\n",
        "        outputs_recon = pretrained_mod(recons.cuda(gpulist[0]))\n",
        "        outputs_orig = pretrained_mod(image.cuda(gpulist[0]))\n",
        "        _, predicted_recon = torch.max(outputs_recon, 1)\n",
        "        _, predicted_orig = torch.max(outputs_orig, 1)\n",
        "        total += image.size(0)\n",
        "        correct_recon += (predicted_recon == class_label.cuda(gpulist[0])).sum()\n",
        "        correct_orig += (predicted_orig == class_label.cuda(gpulist[0])).sum()\n",
        "\n",
        "        if target == -1:\n",
        "            fooled += (predicted_recon != predicted_orig).sum()\n",
        "        else:\n",
        "            fooled += (predicted_recon == target).sum()\n",
        "\n",
        "        if itr % 50 == 1:\n",
        "            print('Images evaluated:', (itr*testBatchSize))\n",
        "            # undo normalize image color channels\n",
        "            delta_im_temp = torch.zeros(delta_im.size())\n",
        "            for c2 in range(3):\n",
        "                recons[:,c2,:,:] = (recons[:,c2,:,:] * stddev_arr[c2]) + mean_arr[c2]\n",
        "                image[:,c2,:,:] = (image[:,c2,:,:] * stddev_arr[c2]) + mean_arr[c2]\n",
        "                delta_im_temp[:,c2,:,:] = (delta_im[:,c2,:,:] * stddev_arr[c2]) + mean_arr[c2]\n",
        "            if not os.path.exists(expname):\n",
        "                os.mkdir(expname)\n",
        "\n",
        "            post_l_inf = (recons - image[0:recons.size(0)]).abs().max() * 255.0\n",
        "            print(\"Specified l_inf:\", mag_in, \"| maximum l_inf of generated perturbations: %.2f\" % (post_l_inf.item()))\n",
        "\n",
        "            torchvision.utils.save_image(recons, expname+'/reconstructed_{}.png'.format(itr))\n",
        "            torchvision.utils.save_image(image, expname+'/original_{}.png'.format(itr))\n",
        "            torchvision.utils.save_image(delta_im_temp, expname+'/delta_im_{}.png'.format(itr))\n",
        "            print('Saved images.')\n",
        "\n",
        "    test_acc_history.append((100.0 * correct_recon / total))\n",
        "    test_fooling_history.append((100.0 * fooled / total))\n",
        "    print('Accuracy of the pretrained network on reconstructed images: %.2f%%' % (100.0 * float(correct_recon) / float(total)))\n",
        "    print('Accuracy of the pretrained network on original images: %.2f%%' % (100.0 * float(correct_orig) / float(total)))\n",
        "    if target == -1:\n",
        "        print('Fooling ratio: %.2f%%' % (100.0 * float(fooled) / float(total)))\n",
        "    else:\n",
        "        print('Top-1 Target Accuracy: %.2f%%' % (100.0 * float(fooled) / float(total)))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IGctB5XZO4oF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "U_loaded = torch.load(explicit_U)\n",
        "\n",
        "#U_loaded = U_loaded.expand(testBatchSize, U_loaded.size(1), U_loaded.size(2), U_loaded.size(3))\n",
        "#delta_im = normalize_and_scale(U_loaded, 'test')\n",
        "U_loaded"
      ],
      "metadata": {
        "id": "PI6kHu3aKIgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_and_scale(delta_im, mode='train'):\n",
        "\n",
        "    if fool_mod == 'incv3':\n",
        "        delta_im = nn.ConstantPad2d((0,-1,-1,0),0)(delta_im)\n",
        "    delta_im = delta_im + 1 \n",
        "    delta_im = delta_im * 0.5 \n",
        "\n",
        "    # normalize image color channels\n",
        "    for c in range(3):\n",
        "        delta_im[:,c,:,:] = (delta_im[:,c,:,:].clone() - mean_arr[c]) / stddev_arr[c]\n",
        "\n",
        "    # threshold each channel of each image in deltaIm according to inf norm\n",
        "    # do on a per image basis as the inf norm of each image could be different\n",
        "    bs = batch_size if (mode == 'train') else testBatchSize\n",
        "    for i in range(bs):\n",
        "        # do per channel l_inf normalization\n",
        "        for ci in range(3):\n",
        "            l_inf_channel = delta_im[i,ci,:,:].detach().abs().max()\n",
        "            mag_in_scaled_c = mag_in/(255.0*stddev_arr[ci])\n",
        "            #gpu_id = gpulist[1] if n_gpu > 1 else gpulist[0]\n",
        "            delta_im[i,ci,:,:] = delta_im[i,ci,:,:].clone() * np.minimum(1.0, mag_in_scaled_c / l_inf_channel.cpu().numpy())\n",
        "\n",
        "    return delta_im\n"
      ],
      "metadata": {
        "id": "iADJ87rIemzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PEElU-jKsF_S"
      },
      "outputs": [],
      "source": [
        "def checkpoint_dict(epoch): \n",
        "    netG.eval()\n",
        "    global best_fooling\n",
        "    if not os.path.exists(expname):\n",
        "        os.mkdir(expname)\n",
        "\n",
        "    task_label = \"foolrat\" if target == -1 else \"top1target\"\n",
        "\n",
        "    net_g_model_out_path = expname + \"/netG_model_epoch_{}_\".format(epoch) + task_label + \"_{}.pth\".format(test_fooling_history[epoch-1])\n",
        "    if perturbation_type == 'universal':\n",
        "        u_out_path = expname + \"/U_out/U_epoch_{}_\".format(epoch) + task_label + \"_{}.pth\".format(test_fooling_history[epoch-1])\n",
        "    if test_fooling_history[epoch-1] > best_fooling:\n",
        "        best_fooling = test_fooling_history[epoch-1]\n",
        "        torch.save(netG.state_dict(), net_g_model_out_path)\n",
        "        if perturbation_type == 'universal':\n",
        "            torch.save(netG(noise_te[0:1]), u_out_path)\n",
        "        print(\"Checkpoint saved to {}\".format(net_g_model_out_path))\n",
        "    else:\n",
        "        print(\"No improvement:\", test_fooling_history[epoch-1], \"Best:\", best_fooling)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HdibeuRdEf2t"
      },
      "outputs": [],
      "source": [
        "def print_history():\n",
        "    # plot history for training loss\n",
        "    if mode == 'train':\n",
        "        plt.plot(train_loss_history)\n",
        "        plt.title('Model Training Loss')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.xlabel('Iteration')\n",
        "        plt.legend(['Training Loss'], loc='upper right')\n",
        "        plt.savefig(expname+'/reconstructed_loss_'+mode+'.png')\n",
        "        plt.clf()\n",
        "        plt.show()\n",
        "\n",
        "    # plot history for classification testing accuracy and fooling ratio\n",
        "    plt.plot(test_acc_history)\n",
        "    plt.title('Model Testing Accuracy')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Testing Classification Accuracy'], loc='upper right')\n",
        "    plt.savefig(expname+'/reconstructed_acc_'+mode+'.png')\n",
        "    plt.clf()\n",
        "    plt.show()\n",
        "\n",
        "    plt.plot(test_fooling_history)\n",
        "    plt.title('Model Testing Fooling Ratio')\n",
        "    plt.ylabel('Fooling Ratio')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Testing Fooling Ratio'], loc='upper right')\n",
        "    plt.savefig(expname+'/reconstructed_foolrat_'+mode+'.png')\n",
        "    plt.show()\n",
        "    print(\"Saved plots.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if mode == 'train':\n",
        "    for epoch in range(1, nEpochs + 1):\n",
        "        train(epoch)\n",
        "        print('Testing....')\n",
        "        test()\n",
        "        checkpoint_dict(epoch)\n",
        "    print_history()\n",
        "elif mode == 'test':\n",
        "    print('Testing...')\n",
        "    test()\n",
        "    print_history()"
      ],
      "metadata": {
        "id": "av0AdwoqCD5h"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "chocoBelgium_GenerativeAdversarialPerturbations.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}